{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import hcp_utils as hcp\n",
    "import nibabel as nib\n",
    "import json\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset():\n",
    "    def __init__(self, BIDS_path):\n",
    "        self.BIDS_path = BIDS_path\n",
    "        if self.BIDS_path is not None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"The path to the dataset in BIDS format must be specified (BIDS_path).\")\n",
    "        self.data_description_path = self.BIDS_path + '/dataset_description.json'\n",
    "        self.participant_data_path = self.BIDS_path + '/participants.tsv'\n",
    "        self._participant_data = pd.read_csv(self.participant_data_path, sep = '\\t')\n",
    "        self._name = None\n",
    "        self._data_description = None\n",
    "        self._subjects = None\n",
    "        self._group = None\n",
    "\n",
    "    @property\n",
    "    def participant_data(self):\n",
    "        if self._participant_data is None:\n",
    "            self._participant_data = pd.read_csv(self.participant_data_path, sep = '\\t')\n",
    "        return self._participant_data\n",
    "\n",
    "    @property\n",
    "    def subjects(self):\n",
    "        if self._subjects is None:\n",
    "            self._subjects = self._participant_data['participant_id'].values\n",
    "        return self._subjects\n",
    "\n",
    "    @property\n",
    "    def group(self):\n",
    "        if self._group is None:\n",
    "            self._group = np.unique(self._participant_data['group'].values)\n",
    "        return self._group\n",
    "    \n",
    "    @property\n",
    "    def data_description(self):\n",
    "        if self._data_description is None:\n",
    "            self._data_description = json.load(open(self.data_description_path))\n",
    "        return self._data_description\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        if self._name is None:\n",
    "            self._name = self.data_description['Name']\n",
    "        return self._name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dataset(Name={self.name},\\nGroup(s)={self.group},\\nSubjects={self.subjects},\\nData_Path={self.BIDS_path})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2475362527.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [87], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    imputer = SimpleImputer(strategy='mean')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class FmriPreppedDataSet(RawDataset):\n",
    "\n",
    "    def __init__(self, BIDS_path):\n",
    "        super().__init__(BIDS_path)\n",
    "        self.data_path = self.BIDS_path + '/derivatives'\n",
    "        self.data_path = self._find_sub_dirs()\n",
    "    def __repr__(self):\n",
    "        return f'Dataset(Group(s)={self.group},\\n Subjects={self.subjects},\\n Data_Path={self.data_path})'\n",
    "    \n",
    "    def _find_sub_dirs(self):\n",
    "        path_not_found = True\n",
    "        while path_not_found:\n",
    "            subdirs = os.listdir(self.data_path)\n",
    "            for subdir in subdirs:\n",
    "                if any(subdir.startswith('sub-') for subdir in subdirs):\n",
    "                        path_not_found = False\n",
    "                else:\n",
    "                    if os.path.isdir(os.path.join(self.data_path, subdir)):\n",
    "                        self.data_path = os.path.join(self.data_path, subdir)\n",
    "        return self.data_path\n",
    "    \n",
    "    def get_sessions(self, subject):\n",
    "        subject_dir = f'{self.data_path}/sub-{subject}'\n",
    "        subdirs = os.listdir(subject_dir)\n",
    "        session_names = []\n",
    "        for subdir in subdirs:\n",
    "            if subdir.startswith('ses-'):\n",
    "                session_names.append(subdir[4:])\n",
    "        return session_names\n",
    "    \n",
    "    def _impute_nans_confounds(dataframe, pick_confounds = None):\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        if pick_confounds == None:\n",
    "            pick_confounds = np.loadtxt('PyConn/PyConn/preprocessing/default_confounds.txt', dtype = 'str')\n",
    "        if isinstance(pick_confounds, (list, np.ndarray)):\n",
    "            df_no_nans = pd.DataFrame(imputer.fit_transform(dataframe), columns=dataframe.columns)[pick_confounds]\n",
    "        else:\n",
    "            df_no_nans = pd.DataFrame(imputer.fit_transform(dataframe), columns=dataframe.columns)\n",
    "        return df_no_nans\n",
    "    \n",
    "    def get_confounds(self, subject, pick_confounds = None, no_nans = True):\n",
    "        subject = \"sub-\" + subject\n",
    "        if pick_confounds == None:\n",
    "            pick_confounds = np.loadtxt('PyConn/PyConn/preprocessing/default_confounds.txt', dtype = 'str')\n",
    "        confounds_suffix = \"confounds_timeseries.tsv\"\n",
    "        func_dir = os.path.join(self.data_path, subject, \"func\", \"\")\n",
    "        confounds_path = os.path.join(func_dir, [filename for filename in os.listdir(func_dir) if confounds_suffix in filename][0])\n",
    "        confounds = pd.read_csv(confounds_path, sep = '\\t')\n",
    "        return confounds\n",
    "    \n",
    "    def get_confounds(self, subject, no_nans = True, pick_columns = None):\n",
    "        confound_paths = []\n",
    "        confound_list = []\n",
    "        subject_dir = os.path.join(self.data_path, f'sub-{subject}')\n",
    "        session_names = get_sessions(subject)\n",
    "        if len(session_names) != 0:\n",
    "            for session_name in session_names:\n",
    "                session_dir = os.path.join(subject_dir, f'ses-{session_name}', 'func')\n",
    "                if os.path.exists(session_dir):\n",
    "                    confound_files = [os.path.join(session_dir, f) for f in os.listdir(session_dir) if f.endswith('confounds_timeseries.tsv')]\n",
    "                    confound_paths.extend(confound_files)\n",
    "            if no_nans == True:\n",
    "                for confounds_path in confound_paths:\n",
    "                    confounds = pd.read_csv(confounds_path, sep = '\\t')\n",
    "                    confounds = self._impute_nans_confounds(confounds, pick_columns = pick_columns)\n",
    "                    confound_list.append(confounds)\n",
    "            else:\n",
    "                for confounds_path in confound_paths:\n",
    "                    confounds = pd.read_csv(confounds_path, sep = '\\t')\n",
    "                    confound_list.append(confounds)\n",
    "        return confound_list\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FmriPreppedDataSet(BIDS_path = '/Users/VictoriaShevchenko/Documents/Python_pour_scientifiques/PyConn/PyConn/data/depression_bezmaternykh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
