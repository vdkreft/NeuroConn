{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import hcp_utils as hcp\n",
    "import nibabel as nib\n",
    "import json\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from nilearn import signal\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset():\n",
    "    def __init__(self, BIDS_path):\n",
    "        self.BIDS_path = BIDS_path\n",
    "        if self.BIDS_path is not None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"The path to the dataset in BIDS format must be specified (BIDS_path).\")\n",
    "        self.data_description_path = self.BIDS_path + '/dataset_description.json'\n",
    "        self.participant_data_path = self.BIDS_path + '/participants.tsv'\n",
    "        self._participant_data = pd.read_csv(self.participant_data_path, sep = '\\t')\n",
    "        self._name = None\n",
    "        self._data_description = None\n",
    "        self._subjects = None\n",
    "        self._group = None\n",
    "\n",
    "    @property\n",
    "    def participant_data(self):\n",
    "        if self._participant_data is None:\n",
    "            self._participant_data = pd.read_csv(self.participant_data_path, sep = '\\t')\n",
    "        return self._participant_data\n",
    "\n",
    "    @property\n",
    "    def subjects(self):\n",
    "        if self._subjects is None:\n",
    "            self._subjects = self._participant_data['participant_id'].values\n",
    "            self._subjects = np.array([i[4:] for i in self._subjects])\n",
    "        return self._subjects\n",
    "\n",
    "    @property\n",
    "    def group(self):\n",
    "        if self._group is None:\n",
    "            self._group = np.unique(self._participant_data['group'].values)\n",
    "        return self._group\n",
    "    \n",
    "    @property\n",
    "    def data_description(self):\n",
    "        if self._data_description is None:\n",
    "            self._data_description = json.load(open(self.data_description_path))\n",
    "        return self._data_description\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        if self._name is None:\n",
    "            self._name = self.data_description['Name']\n",
    "        return self._name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dataset(Name={self.name},\\nGroup(s)={self.group},\\nSubjects={self.subjects},\\nData_Path={self.BIDS_path})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FmriPreppedDataSet(RawDataset):\n",
    "\n",
    "    def __init__(self, BIDS_path):\n",
    "        super().__init__(BIDS_path)\n",
    "        self.data_path = self.BIDS_path + '/derivatives'\n",
    "        self.data_path = self._find_sub_dirs()\n",
    "    def __repr__(self):\n",
    "        return f'Dataset(Group(s)={self.group},\\n Subjects={self.subjects},\\n Data_Path={self.data_path})'\n",
    "    \n",
    "    def _find_sub_dirs(self):\n",
    "        path_not_found = True\n",
    "        while path_not_found:\n",
    "            subdirs = os.listdir(self.data_path)\n",
    "            for subdir in subdirs:\n",
    "                if any(subdir.startswith('sub-') for subdir in subdirs):\n",
    "                        path_not_found = False\n",
    "                else:\n",
    "                    if os.path.isdir(os.path.join(self.data_path, subdir)):\n",
    "                        self.data_path = os.path.join(self.data_path, subdir)\n",
    "        return self.data_path\n",
    "    \n",
    "    def get_ts_paths(self, subject): # needs to beadaptred to multiple sessions\n",
    "        subject_dir = os.path.join(self.data_path, f'sub-{subject}', 'func')\n",
    "        ts_paths = [f'{subject_dir}/{i}' for i in os.listdir(subject_dir) if i.endswith('MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz')] #sub-01_task-rest_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz\n",
    "        return ts_paths\n",
    "    \n",
    "    def get_sessions(self, subject):\n",
    "        subject_dir = f'{self.data_path}/sub-{subject}'\n",
    "        subdirs = os.listdir(subject_dir)\n",
    "        session_names = []\n",
    "        for subdir in subdirs:\n",
    "            if subdir.startswith('ses-'):\n",
    "                session_names.append(subdir[4:])\n",
    "        return session_names\n",
    "    \n",
    "    def _impute_nans_confounds(self, dataframe, pick_confounds = None):\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        if pick_confounds is None:\n",
    "            pick_confounds = np.loadtxt('PyConn/PyConn/preprocessing/default_confounds.txt', dtype = 'str')\n",
    "        if isinstance(pick_confounds, (list, np.ndarray)):\n",
    "            df_no_nans = pd.DataFrame(imputer.fit_transform(dataframe), columns=dataframe.columns)[pick_confounds]\n",
    "        else:\n",
    "            df_no_nans = pd.DataFrame(imputer.fit_transform(dataframe), columns=dataframe.columns)\n",
    "        return df_no_nans\n",
    "    \n",
    "    def get_confounds(self, subject, no_nans = True, pick_confounds = None):\n",
    "        if pick_confounds == None:\n",
    "            pick_confounds = np.loadtxt('PyConn/PyConn/preprocessing/default_confounds.txt', dtype = 'str')\n",
    "\n",
    "        subject_dir = os.path.join(self.data_path, f'sub-{subject}')\n",
    "        session_names = self.get_sessions(subject)\n",
    "\n",
    "        if len(session_names) != 0:\n",
    "            confound_paths = []\n",
    "            confound_list = []\n",
    "            for session_name in session_names:\n",
    "                session_dir = os.path.join(subject_dir, f'ses-{session_name}', 'func')\n",
    "                if os.path.exists(session_dir):\n",
    "                    confound_files = [os.path.join(session_dir, f) for f in os.listdir(session_dir) if f.endswith('confounds_timeseries.tsv')]\n",
    "                    confound_paths.extend(confound_files)\n",
    "                    \n",
    "            if no_nans == True:\n",
    "                for confounds_path in confound_paths:\n",
    "                    confounds = pd.read_csv(confounds_path, sep = '\\t')\n",
    "                    confounds = self._impute_nans_confounds(confounds)\n",
    "                    confound_list.append(confounds)\n",
    "            else:\n",
    "                for confounds_path in confound_paths:\n",
    "                    confounds = pd.read_csv(confounds_path, sep = '\\t')[pick_confounds]\n",
    "                    confound_list.append(confounds)\n",
    "        else:\n",
    "            func_dir = os.path.join(subject_dir, \"func\", \"\")\n",
    "            confound_files = [os.path.join(func_dir, f) for f in os.listdir(func_dir) if f.endswith('confounds_timeseries.tsv')]\n",
    "            if no_nans == True:\n",
    "                confound_list = [self._impute_nans_confounds(pd.read_csv(i, sep = '\\t'), pick_confounds) for i in confound_files]\n",
    "            else:\n",
    "                confound_list = [pd.read_csv(i, sep = '\\t') for i in confound_files]\n",
    "\n",
    "        return confound_list\n",
    "    \n",
    "    def parcellate(self, subjects = None, parcellation = 'schaefer', n_parcels = 1000, gsr = False):\n",
    "        if subjects is None:\n",
    "            subjects = self.subjects\n",
    "        elif not isinstance(subjects, (list, np.ndarray)):\n",
    "            subjects = [subjects]\n",
    "        parc_ts_list = []\n",
    "        for subject in subjects:\n",
    "            subject_ts_paths = self.get_ts_paths(subject)\n",
    "            confounds = self.get_confounds(subject)\n",
    "            if parcellation == 'schaefer':\n",
    "                atlas = datasets.fetch_atlas_schaefer_2018(n_rois=n_parcels, yeo_networks=7, resolution_mm=1, base_url= None, resume=True, verbose=1)\n",
    "            masker =  NiftiLabelsMasker(labels_img=atlas.maps, standardize=True, memory='nilearn_cache', verbose=5)\n",
    "            for subject_ts, subject_confounds in zip(subject_ts_paths, confounds):\n",
    "                print(subject_confounds)\n",
    "                if gsr == False:\n",
    "                    parc_ts = masker.fit_transform(subject_ts, confounds = subject_confounds.drop(\"global_signal\", axis = 1))\n",
    "                    parc_ts_list.append(parc_ts)\n",
    "                else:\n",
    "                    parc_ts = masker.fit_transform(subject_ts, confounds = subject_confounds)\n",
    "                    parc_ts_list.append(parc_ts)\n",
    "        return parc_ts_list\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FmriPreppedDataSet(BIDS_path = '/Users/VictoriaShevchenko/Documents/Python_pour_scientifiques/PyConn/PyConn/data/depression_bezmaternykh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    global_signal          csf  white_matter   trans_x  trans_x_derivative1  \\\n",
      "0      976.179111  1135.008838   1085.977325 -0.011416            -0.000009   \n",
      "1      975.927935  1133.604487   1085.407589 -0.000031             0.011386   \n",
      "2      977.382597  1134.083297   1087.860405 -0.011279            -0.011248   \n",
      "3      978.010885  1135.508196   1087.812419 -0.011284            -0.000005   \n",
      "4      976.452445  1134.290473   1086.856216 -0.005518             0.005766   \n",
      "..            ...          ...           ...       ...                  ...   \n",
      "95     976.381986  1131.225243   1086.363948 -0.016410             0.000000   \n",
      "96     977.550177  1132.801917   1084.471060 -0.016441            -0.000031   \n",
      "97     979.437945  1136.661441   1088.583865 -0.016489            -0.000048   \n",
      "98     977.163677  1132.414469   1086.640938 -0.016441             0.000048   \n",
      "99     978.398509  1135.053541   1086.649081 -0.012302             0.004138   \n",
      "\n",
      "    trans_x_derivative1_power2  trans_x_power2   trans_y  trans_y_derivative1  \\\n",
      "0                 1.900818e-05    1.303365e-04 -0.018655            -0.001802   \n",
      "1                 1.296369e-04    9.411949e-10  0.000006             0.018662   \n",
      "2                 1.265157e-04    1.272068e-04  0.000012             0.000006   \n",
      "3                 2.401000e-11    1.273174e-04 -0.019613            -0.019625   \n",
      "4                 3.324387e-05    3.044557e-05 -0.012237             0.007376   \n",
      "..                         ...             ...       ...                  ...   \n",
      "95                0.000000e+00    2.692881e-04 -0.180955             0.028606   \n",
      "96                9.734400e-10    2.703131e-04 -0.217721            -0.036766   \n",
      "97                2.275290e-09    2.718838e-04 -0.188335             0.029386   \n",
      "98                2.332890e-09    2.702933e-04 -0.219072            -0.030737   \n",
      "99                1.712553e-05    1.513466e-04 -0.197008             0.022064   \n",
      "\n",
      "    trans_y_power2  ...  rot_x_derivative1_power2  rot_x_power2     rot_y  \\\n",
      "0     3.480277e-04  ...              8.725376e-08  2.068764e-08  0.000536   \n",
      "1     3.897005e-11  ...              2.068764e-08  0.000000e+00  0.000348   \n",
      "2     1.411534e-10  ...              3.301380e-08  3.301380e-08  0.000461   \n",
      "3     3.846894e-04  ...              3.301380e-08  0.000000e+00  0.000267   \n",
      "4     1.497515e-04  ...              0.000000e+00  0.000000e+00  0.000616   \n",
      "..             ...  ...                       ...           ...       ...   \n",
      "95    3.274471e-02  ...              3.220676e-09  6.817937e-07 -0.000896   \n",
      "96    4.740243e-02  ...              1.142526e-08  5.167008e-07 -0.001112   \n",
      "97    3.547007e-02  ...              6.869117e-08  9.621825e-07 -0.001443   \n",
      "98    4.799254e-02  ...              1.408021e-07  3.668398e-07 -0.001363   \n",
      "99    3.881215e-02  ...              3.667841e-07  1.467248e-06 -0.001248   \n",
      "\n",
      "    rot_y_derivative1  rot_y_derivative1_power2  rot_y_power2     rot_z  \\\n",
      "0           -0.000018              2.372968e-08  2.871427e-07  0.000528   \n",
      "1           -0.000188              3.524368e-08  1.211903e-07  0.000555   \n",
      "2            0.000113              1.269228e-08  2.123219e-07  0.000472   \n",
      "3           -0.000194              3.768529e-08  7.110596e-08  0.000251   \n",
      "4            0.000350              1.223565e-07  3.800131e-07  0.000229   \n",
      "..                ...                       ...           ...       ...   \n",
      "95           0.000000              0.000000e+00  8.020922e-07 -0.002548   \n",
      "96          -0.000216              4.666205e-08  1.235677e-06 -0.002548   \n",
      "97          -0.000331              1.096405e-07  2.081470e-06 -0.002548   \n",
      "98           0.000079              6.309125e-09  1.858587e-06 -0.002616   \n",
      "99           0.000116              1.340501e-08  1.556306e-06 -0.002563   \n",
      "\n",
      "    rot_z_derivative1  rot_z_power2  rot_z_derivative1_power2  \n",
      "0           -0.000031  2.786436e-07              1.902357e-08  \n",
      "1            0.000027  3.083481e-07              7.520758e-10  \n",
      "2           -0.000083  2.226764e-07              6.956394e-09  \n",
      "3           -0.000221  6.311651e-08              4.868907e-08  \n",
      "4           -0.000023  5.225842e-08              5.120716e-10  \n",
      "..                ...           ...                       ...  \n",
      "95           0.000000  6.493323e-06              0.000000e+00  \n",
      "96           0.000000  6.493323e-06              0.000000e+00  \n",
      "97           0.000000  6.493323e-06              0.000000e+00  \n",
      "98          -0.000068  6.842096e-06              4.561652e-09  \n",
      "99           0.000053  6.568200e-06              2.797352e-09  \n",
      "\n",
      "[100 rows x 27 columns]\n",
      "[NiftiLabelsMasker.fit_transform] loading data from /Users/VictoriaShevchenko/nilearn_data/schaefer_2018/Schaefer2018_1000Parcels_7Networks_order_FSLMNI152_1mm.nii.gz\n",
      "Resampling labels\n",
      "[Memory]0.5s, 0.0min    : Loading _filter_and_extract...\n",
      "__________________________________filter_and_extract cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.34639683,  0.87860435,  0.5665479 , ..., -0.58821434,\n",
       "          0.7506233 ,  0.38765103],\n",
       "        [ 1.9045569 ,  1.2167786 ,  1.1301713 , ..., -0.42591262,\n",
       "          0.88393086,  0.64971757],\n",
       "        [-1.2253412 , -1.5401714 , -0.8476285 , ...,  0.91552854,\n",
       "         -1.3531073 , -0.807112  ],\n",
       "        ...,\n",
       "        [-0.4155177 , -0.90086687, -0.7759805 , ..., -0.09707052,\n",
       "         -0.49771705, -0.3119472 ],\n",
       "        [ 0.45147553, -0.40153697,  0.23378395, ..., -0.61115736,\n",
       "          0.16013454,  0.6397856 ],\n",
       "        [ 1.0095524 ,  0.59423864,  0.9778209 , ...,  0.03881342,\n",
       "         -0.62739056, -0.8561374 ]], dtype=float32)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.parcellate(\"01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
